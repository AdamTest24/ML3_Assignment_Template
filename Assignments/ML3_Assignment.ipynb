{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55ebb43",
   "metadata": {},
   "source": [
    "## L2D Assignment - Machine Learning 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d1f7a",
   "metadata": {},
   "source": [
    "This notebook contains your assignment questions for the **Refinement** lesson. Please attempt and complete all questions. The topics this assignment will assess are:\n",
    "\n",
    "1. Refinement\n",
    "\n",
    "\n",
    "When you have completed your assignment, please commit the changes to your GitHub repository's 'Assignments' folder, as instructed in the [Assignments section](https://learntodiscover.github.io/L2D-Handbook/section7.html) of the [L2D Handbook](https://learntodiscover.github.io/L2D-Handbook).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800c549",
   "metadata": {},
   "source": [
    "As a suggestion, take the [breast cancer dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer).\n",
    "\n",
    "The breast cancer data can be imported from the `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90325991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b15f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mgrid, linspace, c_, arange, mean, array\n",
    "from numpy.random import uniform, seed\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib.pyplot import subplots, axes, scatter, xticks, show\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "RANDOM_STATE = 111\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'AdaBoost (Random Forest)': AdaBoostClassifier(RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "    'Extra Trees': ExtraTreesClassifier(random_state=RANDOM_STATE),\n",
    "    'AdaBoost (Extra Tree)': AdaBoostClassifier(ExtraTreesClassifier(random_state=RANDOM_STATE)),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'SVC (RBF)': SVC(random_state=RANDOM_STATE),\n",
    "    'SVC (Linear)': LinearSVC(random_state=RANDOM_STATE, dual=False),\n",
    "    'Multi-layer Perceptron': MLPClassifier(max_iter=5000, random_state=RANDOM_STATE)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3627c2",
   "metadata": {},
   "source": [
    "**Note**: Notice that the linear Support Vector classifier is imported with the keyword argument `dual=False`. This is to reduce the number of (pink) warnings that occur when the classifier struggles to find a good solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d551b",
   "metadata": {},
   "source": [
    "1. Using all features create a summary boxplot to see the medians and distributions of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929f98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b429dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24881f7",
   "metadata": {},
   "source": [
    "2. Train the above introduced classifiers using the train_test split to generate testing and training data and pick a small training set of e.g. 10% to make the classification task difficult. Obtain the recall scores to compare classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b62302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93371e2b",
   "metadata": {},
   "source": [
    "3. Plot the confusion matrix for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056d16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6489f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0a619d6",
   "metadata": {},
   "source": [
    "4. Do a permutation test with default settings to get the p-values to reject the null hypothesis that the scores are compatible with random predictions. If it takes too long, reduce `n_permutations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25199253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78abc695",
   "metadata": {},
   "source": [
    "\n",
    "5. Repeat the workflow with normalised data and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a069c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9340f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba6d9d80",
   "metadata": {},
   "source": [
    "6. Perform a hyperparameter tuning with the Random Forest classifier. For the optimal parameter settings, re-run the training and plot the feature importances to see the contributions of each feature to the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4612d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106304ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e33da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795df98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
